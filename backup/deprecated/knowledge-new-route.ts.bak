import { NextRequest, NextResponse } from 'next/server';
import { auth } from '@/app/(auth)/auth';
import { createKnowledgeDocument, createKnowledgeChunk, updateKnowledgeDocument } from '@/lib/db/queries';
import { fetchWebContent } from '@/lib/knowledge/urlProcessor/index';

// Ensure dynamic rendering and disable caching
export const dynamic = 'force-dynamic';

/**
 * API endpoint for handling knowledge document uploads
 */
export async function POST(req: NextRequest) {
  console.log('[KNOWLEDGE-NEW] POST request received');
  
  try {
    // Get user session
    const session = await auth();
    
    if (!session?.user) {
      console.log('[KNOWLEDGE-NEW] Unauthorized access attempt');
      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
    }
    
    const userId = session.user.id as string;
    console.log(`[KNOWLEDGE-NEW] Authenticated user: ${userId}`);
    
    // Parse form data
    const formData = await req.formData();
    console.log('[KNOWLEDGE-NEW] Successfully parsed form data');
    
    // Get essential fields
    const title = formData.get('title') as string;
    const description = formData.get('description') as string || '';
    const sourceType = formData.get('sourceType') as 'text' | 'url' | 'audio';
    
    if (!title) {
      return NextResponse.json({ error: 'Title is required' }, { status: 400 });
    }
    
    if (!sourceType) {
      return NextResponse.json({ error: 'Source type is required' }, { status: 400 });
    }
    
    console.log(`[KNOWLEDGE-NEW] Creating document: ${title}, type: ${sourceType}`);
    
    // Handle different source types and set accurate file sizes
    let fileSize = 'unknown';
    let fileType = 'text/plain';
    
    if (sourceType === 'text') {
      const content = formData.get('content') as string || '';
      fileSize = `${content.length} chars`;
      fileType = 'text/plain';
    } else if (sourceType === 'url') {
      const sourceUrl = formData.get('sourceUrl') as string || '';
      const notes = formData.get('notes') as string || '';
      // Size is based on URL + notes + estimate for web content
      const urlSize = sourceUrl.length + notes.length + 1000;
      fileSize = `${urlSize} chars`;
      fileType = 'text/html';
    } else if (sourceType === 'audio') {
      const audioFile = formData.get('file') as File;
      const audioBlob = formData.get('audioBlob') as Blob;
      // For audio, estimate based on file size or recording length
      if (audioFile) {
        // Roughly estimate 1KB = 500 characters of transcribed text
        const estimatedChars = Math.round((audioFile.size / 1024) * 500);
        fileSize = `${estimatedChars} chars`;
      } else if (audioBlob) {
        const estimatedChars = Math.round((audioBlob.size / 1024) * 500);
        fileSize = `${estimatedChars} chars`;
      } else {
        fileSize = '2000 chars'; // Fallback
      }
      fileType = 'audio/webm';
    }
    
    // Create a document in the database
    const document = await createKnowledgeDocument({
      userId,
      title,
      description,
      sourceType,
      sourceUrl: formData.get('sourceUrl') as string || '',
      fileSize,
      fileType,
    });
    
    console.log(`[KNOWLEDGE-NEW] Document created with ID: ${document.id}`);

    // Handle text content - create basic chunks
    if (sourceType === 'text') {
      const content = formData.get('content') as string;
      if (content) {
        console.log(`[KNOWLEDGE-NEW] Processing text content (${content.length} chars)`);
        
        // Simple chunking - split by paragraphs or fixed size if too large
        const chunks = splitTextIntoChunks(content);
        console.log(`[KNOWLEDGE-NEW] Created ${chunks.length} chunks`);
        
        // Store chunks in database
        for (let i = 0; i < chunks.length; i++) {
          await createKnowledgeChunk({
            documentId: document.id,
            content: chunks[i],
            metadata: { index: i },
            chunkIndex: i.toString(),
            embedding: [], // Empty embedding for simplified version
          });
          console.log(`[KNOWLEDGE-NEW] Stored chunk ${i+1}/${chunks.length}`);
        }

        // Mark document as completed
        await updateKnowledgeDocument({
          id: document.id,
          status: 'completed',
        });
        console.log(`[KNOWLEDGE-NEW] Document marked as completed`);
      }
    } else if (sourceType === 'url') {
      const sourceUrl = formData.get('sourceUrl') as string;
      console.log(`[KNOWLEDGE-NEW] Starting URL processing for ${sourceUrl}...`);
      
      // Process URL in the background without waiting for completion
      fetchWebContent({
        documentId: document.id,
        url: sourceUrl,
        userId: userId
      }).catch(processingError => {
        console.error(`[KNOWLEDGE-NEW] Background URL processing error:`, processingError);
        // The error will be handled within the processor and the document status will be updated
      });
      
      console.log(`[KNOWLEDGE-NEW] URL processing started in the background`);
    }
    
    return NextResponse.json({
      success: true,
      id: document.id,
      title: document.title,
      status: document.status,
      message: 'Document created successfully'
    }, { status: 201 });
    
  } catch (error) {
    console.error('[KNOWLEDGE-NEW] Error:', error);
    return NextResponse.json({ 
      error: 'An unexpected error occurred',
      details: error instanceof Error ? error.message : String(error)
    }, { status: 500 });
  }
}

/**
 * Split text into chunks of approximately 800-1000 tokens (simplified version)
 */
function splitTextIntoChunks(text: string): string[] {
  // A simple implementation that splits by paragraphs
  const paragraphs = text.split(/\n\s*\n/);
  const chunks: string[] = [];
  let currentChunk = '';

  for (const paragraph of paragraphs) {
    // Rough estimate: 1 token â‰ˆ 4 characters
    if (currentChunk.length + paragraph.length > 3500) { // ~875 tokens
      chunks.push(currentChunk.trim());
      currentChunk = paragraph;
    } else {
      currentChunk += '\n\n' + paragraph;
    }
  }

  if (currentChunk.trim()) {
    chunks.push(currentChunk.trim());
  }

  // If no paragraphs found or text is very short, just return the whole text
  if (chunks.length === 0) {
    return [text];
  }

  return chunks;
}